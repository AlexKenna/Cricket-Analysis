{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Initialisation\n",
    "This document is concerned with initialising the data to be used throughout the remainder of the project. This section must be completed thoroughly and accurately to ensure optimal outcomes in later stages of this research topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AlexK\\AppData\\Local\\Temp/ipykernel_5232/1522512839.py:10: DtypeWarning: Columns (6,19,85,87,101,103,200,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,233,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,396) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  clean_raw_data()\n",
      "C:\\Users\\AlexK\\AppData\\Local\\Temp/ipykernel_5232/1522512839.py:10: DtypeWarning: Columns (6,19,56,85,87,91,101,103,169,200,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,233,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,266,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,396) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  clean_raw_data()\n",
      "C:\\Users\\AlexK\\AppData\\Local\\Temp/ipykernel_5232/1522512839.py:10: DtypeWarning: Columns (6,19,56,85,87,89,91,101,103,112,114,116,118,120,169,200,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,233,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,266,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,299,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,332,360,363,364,366,367,389,390,396) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  clean_raw_data()\n"
     ]
    }
   ],
   "source": [
    "# Path to library module.\n",
    "from lib.constants import LIBRARY_PATH\n",
    "import sys\n",
    "sys.path.append(LIBRARY_PATH)\n",
    "\n",
    "# Import data cleaning function\n",
    "from lib.clean_raw_data import clean_raw_data\n",
    "\n",
    "# Clean the raw match and delivery data files\n",
    "clean_raw_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Walk-Through of Cleaning Process\n",
    "In this section, the entire cleaning process performed above will be outlined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform necessary imports.\n",
    "import pandas as pd\n",
    "from lib.constants import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Clean Match Data\n",
    "Here, we will perform a basic clean on the match data. This includes performing the following steps:\n",
    "\n",
    "1. Removing unnecessary columns from match data.\n",
    "2. Remoing female formats.\n",
    "3. Removing disability teams.\n",
    "4. Removing international games not involving Australia.\n",
    "5. Removing uncommon match formats.\n",
    "6. Removing international games that are not of 1 Day format.\n",
    "\n",
    "This process is outlined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load match data.\n",
    "match_data = pd.read_csv(DATA_PATH + \"/Matches.txt\", delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Match Id', 'Season Id', 'Season', 'Series Id', 'Series',\n",
       "       'Series Gender Id', 'Series Gender', 'Match Date', 'Match YYMMDD',\n",
       "       'Match Type Id', 'Match Type', 'Ball Type Id', 'Ball Type', 'TeamA Id',\n",
       "       'TeamA', 'TeamA At Home', 'TeamB Id', 'TeamB', 'TeamB At Home',\n",
       "       'Day/Night', 'Venue Id', 'Venue', 'Toss Won By Id', 'Toss Decision Id',\n",
       "       'TeamA Innings1 Closure', 'TeamA Innings2 Closure',\n",
       "       'TeamB Innings1 Closure', 'TeamB Innings2 Closure',\n",
       "       'TeamA 1st Comparison', 'TeamA Result Id', 'TeamA Result',\n",
       "       'TeamBattingIdMatchInnings1', 'TeamBattingMatchInnings1',\n",
       "       'TeamBattingIdMatchInnings2', 'TeamBattingMatchInnings2',\n",
       "       'TeamBattingIdMatchInnings3', 'TeamBattingMatchInnings3',\n",
       "       'TeamBattingIdMatchInnings4', 'TeamBattingMatchInnings4',\n",
       "       'TeamB Result Id', 'TeamB Result', 'TeamA Coach Id',\n",
       "       'TeamA Coach Surname', 'TeamA Coach Other Names', 'TeamB Coach Id',\n",
       "       'TeamB Coach Surname', 'TeamB Coach Other Names', 'Round Id', 'Round',\n",
       "       'Round Number', 'Match Number', 'Data Source'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove unnecessary columns from match data.\n",
    "match_data = match_data[match_data.columns.drop(list(match_data.filter(regex='Official+')))]\n",
    "match_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Removing female formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Male'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove female series from match data.\n",
    "match_data = match_data.loc[match_data[\"Series Gender Id\"] == 1]\n",
    "match_data[\"Series Gender\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Removing disability teams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Australia (M)', 'West Indies (M)', 'Pakistan (M)',\n",
       "       'Sri Lanka (M)', 'South Africa (M)', 'England (M)',\n",
       "       'New Zealand (M)', 'India (M)', 'SA (M)', 'Tas (M)', 'NSW (M)',\n",
       "       'Victoria (M)', 'WA (M)', 'Qld (M)', 'Australia A (M)',\n",
       "       'Zimbabwe (M)', 'Kenya (M)', 'Scotland (M)', 'Bangladesh (M)',\n",
       "       'Ireland (M)', 'Sydney Sixers (M)', 'Melbourne Stars (M)',\n",
       "       'Adelaide Strikers (M)', 'Perth Scorchers  (M)',\n",
       "       'Brisbane Heat (M)', 'Hobart Hurricanes (M)',\n",
       "       'Melbourne Renegades (M)', 'Sydney Thunder (M)', 'Canada (M)',\n",
       "       'Gloucestershire (M)', 'Afghanistan (M)', 'India A (M)',\n",
       "       'South Africa A (M)', 'CA XI (M)', 'India B (M)',\n",
       "       'England Lions (M)'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove disability teams from match data.\n",
    "match_data =  match_data[~match_data.TeamA.str.contains(\"Disability\") | \n",
    "                         ~match_data.TeamB.str.contains(\"Disability\")]\n",
    "match_data[\"TeamA\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Remove international games where Australia is not playing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove international games where Australia is not playing.\n",
    "match_data = match_data[~(match_data.Series.str.contains(\"International\") & ~match_data.TeamA.str.contains(\"Australia\") & ~match_data.TeamB.str.contains(\"Australia\"))]\n",
    "len(match_data[match_data.Series.str.contains(\"International\") & ~match_data.TeamA.str.contains(\"Australia\") & ~match_data.TeamB.str.contains(\"Australia\")][[\"TeamA\", \"TeamB\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Remove uncommon match formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['5 Day', '1 Day', '4 Day', 'Twenty20'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove games that are not T20, 1 Day, 4 Day, or 5 Day formats.\n",
    "match_data = match_data[match_data[\"Match Type Id\"].isin([1,4,5,7])]\n",
    "match_data[\"Match Type\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Remove international matches that are not 1 Day format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['International ODI M', 'Domestic 1st Class M', 'Domestic List A M',\n",
       "       'Domestic T20 M', 'International ICC Trophy M',\n",
       "       'International ODI World Cup M', 'International 1st Class M'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove international games that are not ODI.\n",
    "match_data = match_data[(match_data[\"Match Type Id\"] == 1 & match_data.Series.str.contains(\"International\")) | match_data.Series.str.contains(\"Domestic\")]\n",
    "match_data.Series.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now write this cleaned data to file to be used later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the cleaned data to file.\n",
    "match_data.to_csv(DATA_PATH + \"/Matches_Clean.txt\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Clean Deliveries Data\n",
    "Here, we will perform a basic clean on the deliveries data. This includes performing the following steps:\n",
    "\n",
    "1. Load delivery data only containing relevant matches.\n",
    "2. Remove deliveries to foreign teams.\n",
    "3. Remove deliveries to domestic players that have not played at the international level.\n",
    "4. Remove deliveries to players that have played less than a threshold number of international One-Day games.\n",
    "\n",
    "These steps are outlined below.\n",
    "\n",
    "1. Load delivery data only containing relevant matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AlexK\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3377: DtypeWarning: Columns (6,19,85,87,101,103,200,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,233,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,396) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n",
      "C:\\Users\\AlexK\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3377: DtypeWarning: Columns (6,19,56,85,87,91,101,103,169,200,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,233,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,266,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,396) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n",
      "C:\\Users\\AlexK\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3377: DtypeWarning: Columns (6,19,56,85,87,89,91,101,103,112,114,116,118,120,169,200,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,233,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,266,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,299,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,332,360,363,364,366,367,389,390,396) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    }
   ],
   "source": [
    "# Determine which matches are important for delivery data.\n",
    "match_ids = match_data[\"Match Id\"]\n",
    "\n",
    "# Determine duplicate columns between match and delivery data that should be dropped.\n",
    "match_columns = set(match_data.columns)\n",
    "match_columns.remove(\"Match Id\")\n",
    "\n",
    "# Load delivery data\n",
    "delivery_data = pd.DataFrame()\n",
    "\n",
    "for chunk in pd.read_csv(DATA_PATH + \"/Deliveries.txt\", delimiter=\"\\t\", chunksize=10**6):\n",
    "  chunk = chunk[chunk[\"Match Id\"].isin(match_ids)]\n",
    "  chunk.drop(\n",
    "    [col for col in chunk.columns if col in match_columns], axis=1, inplace=True\n",
    "  )\n",
    "\n",
    "  # Combine filtered deliveries into single dataframe.\n",
    "  delivery_data = pd.concat([delivery_data, chunk])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning the delivery data while in chunks is necessary as the raw dataset is too large to load into memory.\n",
    "\n",
    "2. Remove deliveries to foreign teams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Australia (M)', 'SA (M)', 'Victoria (M)', 'NSW (M)', 'Tas (M)',\n",
       "       'WA (M)', 'Qld (M)', 'Australia A (M)', 'Brisbane Heat (M)',\n",
       "       'Sydney Sixers (M)', 'Melbourne Stars (M)', 'Sydney Thunder (M)',\n",
       "       'Adelaide Strikers (M)', 'Melbourne Renegades (M)',\n",
       "       'Hobart Hurricanes (M)', 'Perth Scorchers  (M)', 'CA XI (M)'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a list of international One Day match IDs.\n",
    "odi_IDs = match_data[match_data[\"Series\"].str.contains(\"International\")][\"Match Id\"].tolist()\n",
    "\n",
    "# Remove deliveries to foreign teams.\n",
    "delivery_data = delivery_data[~(delivery_data[\"Match Id\"].isin(odi_IDs) & ~delivery_data[\"Team Batting\"].str.contains(\"Australia\"))]\n",
    "\n",
    "# Show the remaining batting teams.\n",
    "delivery_data[\"Team Batting\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Remove deliveries to domestic players that have not played at international level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Waugh, Mark', 'Gilchrist, Adam', 'Ponting, Ricky',\n",
       "       'Bevan, Michael', 'Waugh, Steve', 'Martyn, Damien',\n",
       "       'Symonds, Andrew', 'Lee, Shane', 'Fleming, Damien',\n",
       "       'MacGill, Stuart', 'Lee, Brett', 'McGrath, Glen', 'Dale, Adam',\n",
       "       'Warne, Shane', 'Harvey, Ian', 'Blewett, Greg', 'Hayden, Matthew',\n",
       "       'Katich, Simon', 'Slater, Michael', 'Hodge, Brad',\n",
       "       'Lehmann, Darren', 'Haddin, Brad', 'Maher, Jimmy', 'Watson, Shane',\n",
       "       'Gillespie, Jason', 'Williams, Brad', 'Bichel, Andrew',\n",
       "       'Campbell, Ryan', 'Hauritz, Nathan', 'Harris, Ryan',\n",
       "       'White, Cameron', 'Lewis, Michael', 'Manou, Graham',\n",
       "       'Clarke, Michael', 'Wright, Damian', 'Tait, Shaun',\n",
       "       'Hussey, Michael', 'Voges, Adam', 'Ronchi, Luke',\n",
       "       'Doherty, Xavier', 'Cosgrove, Mark', 'Geeves, Brett',\n",
       "       'Jaques, Philp', 'Clark, Stuart', 'Thornely, Dominic',\n",
       "       'Bracken, Nathan', 'Bailey, George', 'North, Marcus',\n",
       "       'Hussey, David', 'Harwood, Shane', 'Ferguson, Callum',\n",
       "       'Marsh, Shaun', 'Hogg, Brad', 'Bollinger, Doug', 'Cullen, Dan',\n",
       "       'Paine, Tim', 'Wade, Matthew', 'Siddle, Peter', 'Nannes, Dirk',\n",
       "       'Forrest, Peter', 'Dorey, Brett', 'Krejza, Jason',\n",
       "       'Hilfenhaus, Ben', 'Hopes, James', 'McKay, Clinton',\n",
       "       'Hughes, Phil', 'Kasprowicz, Michael', 'Christian, Daniel',\n",
       "       'Khawaja, Usman', 'Laughlin, Ben', 'Finch, Aaron',\n",
       "       'Hastings, John', 'Henriques, Moises', 'Smith, Steven',\n",
       "       'Warner, David', 'Cooper, Tom', 'Pattinson, James',\n",
       "       'Nevill, Peter', 'Faulkner, James', 'Stoinis, Marcus',\n",
       "       'Cutting, Ben', 'Rohrer, Ben', 'Doolan, Alex', 'Richardson, Kane',\n",
       "       'Marsh, Mitchell', 'Starc, Mitchell', 'Hazlewood, Josh',\n",
       "       'Coulter-Nile, Nathan', 'Maxwell, Glenn', 'Lynn, Chris',\n",
       "       'Boyce, Cameron', 'Johnson, Mitchell', 'Maddinson, Nic',\n",
       "       'Neser, Michael', 'Burns, Joe', 'Lyon, Nathan Michael',\n",
       "       'Abbott, Sean', 'Cummins, Patrick', 'Sayers, Chadd',\n",
       "       'Handscomb, Peter', 'Mennie, Joe', 'Behrendorff, Jason',\n",
       "       'Boland, Scott', \"Short, D'Arcy\", 'Head, Travis', 'Tremain, Chris',\n",
       "       'Worrall, Daniel', 'Cartwright, Hilton', 'Zampa, Adam',\n",
       "       'Sandhu, Gurinder', 'Agar, Ashton', 'Carey, Alex', 'Ahmed, Fawad',\n",
       "       'Tye, Andrew', 'Turner, Ashton', 'Stanlake, Billy',\n",
       "       'Richardson, Jhye', 'Paris, Joel', 'Labuschagne, Marnus',\n",
       "       'Wildermuth, Jack', 'Renshaw, Matthew', 'Swepson, Mitchell Joseph',\n",
       "       'Heazlett, Sam', 'Green, Cameron'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get deliveries to Australian One Day players.\n",
    "australian_odi_deliveries = delivery_data[delivery_data[\"Match Id\"].isin(odi_IDs)]\n",
    "\n",
    "# Get Australian One Day batters.\n",
    "australian_odi_batters = australian_odi_deliveries[\"Striker Id\"].unique()\n",
    "\n",
    "# Remove deliveries to domestic Australian batters.\n",
    "delivery_data = delivery_data[delivery_data[\"Striker Id\"].isin(australian_odi_batters)]\n",
    "\n",
    "# Print remaining batters.\n",
    "delivery_data[\"Striker\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Remove deliveries to players that have played less than a threshold number of international One-Day games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Waugh, Mark', 'Ponting, Ricky', 'Bevan, Michael', 'Waugh, Steve',\n",
       "       'Symonds, Andrew', 'Lee, Brett', 'Warne, Shane', 'Harvey, Ian',\n",
       "       'Hayden, Matthew', 'Katich, Simon', 'Hodge, Brad',\n",
       "       'Lehmann, Darren', 'Haddin, Brad', 'Maher, Jimmy', 'Watson, Shane',\n",
       "       'Gillespie, Jason', 'Bichel, Andrew', 'Hauritz, Nathan',\n",
       "       'White, Cameron', 'Clarke, Michael', 'Hussey, Michael',\n",
       "       'Voges, Adam', 'Doherty, Xavier', 'Clark, Stuart',\n",
       "       'Bracken, Nathan', 'Bailey, George', 'Hussey, David',\n",
       "       'Ferguson, Callum', 'Marsh, Shaun', 'Hogg, Brad', 'Paine, Tim',\n",
       "       'Wade, Matthew', 'Forrest, Peter', 'Hopes, James',\n",
       "       'McKay, Clinton', 'Hughes, Phil', 'Christian, Daniel',\n",
       "       'Khawaja, Usman', 'Finch, Aaron', 'Hastings, John',\n",
       "       'Henriques, Moises', 'Smith, Steven', 'Warner, David',\n",
       "       'Faulkner, James', 'Stoinis, Marcus', 'Richardson, Kane',\n",
       "       'Marsh, Mitchell', 'Starc, Mitchell', 'Hazlewood, Josh',\n",
       "       'Coulter-Nile, Nathan', 'Maxwell, Glenn', 'Johnson, Mitchell',\n",
       "       'Burns, Joe', 'Lyon, Nathan Michael', 'Cummins, Patrick',\n",
       "       'Handscomb, Peter', \"Short, D'Arcy\", 'Head, Travis', 'Zampa, Adam',\n",
       "       'Agar, Ashton', 'Carey, Alex', 'Labuschagne, Marnus'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract international and domestic deliveries.\n",
    "international_matches = match_data[match_data[\"Series\"].str.contains(\"International\")][\"Match Id\"].tolist()\n",
    "domestic_matches = match_data[match_data[\"Series\"].str.contains(\"Domestic\")][\"Match Id\"].tolist()\n",
    "\n",
    "international_deliveries = delivery_data[delivery_data[\"Match Id\"].isin(international_matches)]\n",
    "domestic_deliveries = delivery_data[delivery_data[\"Match Id\"].isin(domestic_matches)]\n",
    "\n",
    "# Aggregate fields.\n",
    "by_columns = [\"Striker Id\"]\n",
    "aggregates = {\"Match Id\": pd.Series.nunique}\n",
    "\n",
    "# Count number of international matches per remaining batter.\n",
    "international_groupby_data = international_deliveries.groupby(by=by_columns).agg(aggregates)\n",
    "\n",
    "# Count number of domestic matches per remaining batter.\n",
    "domestic_groupby_data = domestic_deliveries.groupby(by=by_columns).agg(aggregates)\n",
    "\n",
    "# Remove batters that have batted in less than 10 international One Day innings.\n",
    "valid_batters = international_groupby_data[international_groupby_data[\"Match Id\"] >= 10].index\n",
    "delivery_data = delivery_data[delivery_data[\"Striker Id\"].isin(valid_batters)]\n",
    "\n",
    "# Remove batters that have batted in less than 10 domestic innings.\n",
    "valid_batters = domestic_groupby_data[domestic_groupby_data[\"Match Id\"] >= 10].index\n",
    "delivery_data = delivery_data[delivery_data[\"Striker Id\"].isin(valid_batters)]\n",
    "\n",
    "# Print remaining batters.\n",
    "delivery_data[\"Striker\"].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Cleaning of Entire Dataset\n",
    "This section tidies the already cleaned data to the final workable state. This includes the following steps:\n",
    "\n",
    "1. Remove matches that contain no delivery data.\n",
    "\n",
    "These steps are outlined below.\n",
    "\n",
    "1. Remove matches that contain no delivery data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract match IDs.\n",
    "match_ids = match_data[\"Match Id\"].unique().tolist()\n",
    "\n",
    "# Extract delivery match IDs.\n",
    "delivery_ids = delivery_data[\"Match Id\"].unique().tolist()\n",
    "\n",
    "# Determine difference.\n",
    "empty_matches = set(match_ids) - set(delivery_ids)\n",
    "\n",
    "# Remove empty match data.\n",
    "match_data = match_data[~(match_data[\"Match Id\"].isin(empty_matches))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Data to File\n",
    "\n",
    "Finally, we will write both datasets back to file in their final cleaned states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the cleaned data to file.\n",
    "match_data.to_csv(DATA_PATH + \"/Matches_Clean.txt\", sep=\"\\t\", index=False)\n",
    "delivery_data.to_csv(DATA_PATH + \"/Deliveries_Clean.txt\", sep=\"\\t\", index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d5f05966c834b7114444b779d720abe0e299bd07f35b3e38633408fa0bc32ead"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
